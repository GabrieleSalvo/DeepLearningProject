{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from ReviewModel import ReviewModel\n",
    "from dataLoader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(tr_loss, val_loss):\n",
    "    plt.plot(tr_loss, label=\"training\")\n",
    "    plt.plot(val_loss, label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = AmznDataLoader( path ='./data/reviews_Amazon_Instant_Video_5.json.gz', maxSeqLength = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReviewModelParam = {\n",
    "    \"max_length\": 60,\n",
    "    \"embedding_dim\": 50,\n",
    "    \"vocab_length\" : data_loader.weight_matrix.shape[0],\n",
    "    \"output_dim\" : 5,\n",
    "    \"batch_size\" : 128,\n",
    "    \"random\":False,\n",
    "    \"first_dropout\" : 0.5,\n",
    "    \"conv_input_channel\": None,\n",
    "    \"conv_output_channel\" : 200,\n",
    "    \"conv_padding\" : 2,\n",
    "    \"conv1_kernel_size\" : 4,\n",
    "    \"conv2_kernel_size\" : 5,\n",
    "    \"maxpool_kernel_size\" : 2,\n",
    "    \"second_dropout\" : 0.3,\n",
    "    \"rnn_input_size\": None,\n",
    "    \"rnn_hidden_size\" : 100,\n",
    "    \"rnn_num_layers\" : 1,\n",
    "    \"first_dense_in\":None,\n",
    "    \"first_dense_out\" : 400,\n",
    "    \"third_dropout\" : 0.15,\n",
    "    \"second_dense_in\" : None,\n",
    "    \"second_dense_out\" : None\n",
    "    }\n",
    "\n",
    "ReviewModelParam[\"conv_input_channel\"] = ReviewModelParam[\"embedding_dim\"]\n",
    "ReviewModelParam[\"rnn_input_size\"] = ReviewModelParam[\"conv_output_channel\"]*2\n",
    "ReviewModelParam[\"first_dense_in\"] = ReviewModelParam[\"max_length\"]//2 * ReviewModelParam[\"rnn_hidden_size\"]\n",
    "ReviewModelParam[\"second_dense_in\"] = ReviewModelParam[\"first_dense_out\"]\n",
    "ReviewModelParam[\"second_dense_out\"] = ReviewModelParam[\"output_dim\"]  ##depends on loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "import torch.optim as optim\n",
    "from skorch.callbacks import EpochScoring,LRScheduler, EarlyStopping\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ('es1',EpochScoring('accuracy')),\n",
    "    ('lrs',LRScheduler()),\n",
    "    ('est',EarlyStopping())    \n",
    "]\n",
    "batch_size = 128\n",
    "device = torch.device(\"cuda\")\n",
    "model = ReviewModel(ReviewModelParam).to(device)\n",
    "#model = DynamicModel(batch_size,parameter_dict=SST1_DATASET_PARAMETERS).to(device)\n",
    "net = NeuralNetClassifier(model,## change dimensionality\n",
    "                          iterator_train__drop_last = True,\n",
    "                          iterator_valid__drop_last = True, \n",
    "                          iterator_train__shuffle = True,\n",
    "                          iterator_valid__shuffle = True,\n",
    "                          max_epochs=100, \n",
    "                          criterion = nn.CrossEntropyLoss,\n",
    "                          optimizer=optim.Adam,\n",
    "                          lr = 0.01,\n",
    "                          # optimizer__param_groups = {('momentum', 0.3)},\n",
    "                          batch_size = batch_size,\n",
    "                          callbacks = callbacks,\n",
    "                          device = device,verbose = 1\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    accuracy    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ----------  ------------  -----------  ------------  -------\n",
      "      1      0.5610        7.8590       0.5610        1.2041  75.9910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ReviewModel(\n",
       "    (embedding): Embedding(52655, 50)\n",
       "    (drop1): Dropout(p=0.5)\n",
       "    (conv1): Conv1d(50, 200, kernel_size=(4,), stride=(1,), padding=(2,))\n",
       "    (conv2): Conv1d(50, 200, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (drop2): Dropout(p=0.3)\n",
       "    (rnn): GRU(400, 100)\n",
       "    (flatten): Flatten()\n",
       "    (fc1): Linear(in_features=3000, out_features=400, bias=True)\n",
       "    (drop3): Dropout(p=0.15)\n",
       "    (fc2): Linear(in_features=400, out_features=5, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.from_numpy(data_loader.X_train).long().to(device)\n",
    "labels = torch.tensor(data_loader.y_train.values).long().to(device)\n",
    "net.fit(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(data_loader.X_test).long().to(device)\n",
    "predictions = net.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix , confusion_matrix\n",
    "conf2 = confusion_matrix(data_loader.y_test[:-2], predictions, labels=[0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,  363],\n",
       "       [   0,    0,    0,    0,  333],\n",
       "       [   0,    0,    0,    0,  839],\n",
       "       [   0,    0,    0,    0, 1687],\n",
       "       [   0,    0,    0,    0, 4202]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open(\"model.pkl\", 'wb') as f:\n",
    "    pickle.dump(\"model\",f)\n",
    "   \n",
    "# load model\n",
    "with open(\"model.pkl\",\"rb\") as f: \n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#todo plot losses\n",
    "#todo plot accuracy\n",
    "#todo confusion matrix\n",
    "history = net.history\n",
    "train_losses = history[:, 'train_loss']\n",
    "valid_losses = history[:, 'valid_loss']\n",
    "\n",
    "accuracy = history[:, 'accuracy']\n",
    "plot_losses(train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight = Variable(torch.cuda.FloatTensor([0.04,0.05,0.11,0.23,0.56])) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
