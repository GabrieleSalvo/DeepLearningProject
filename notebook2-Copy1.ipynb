{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from base import BaseDataLoader\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "# import visdom\n",
    "import random\n",
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmznDataLoader():\n",
    "        def __init__(self):\n",
    "#            df = self.getDF('./data/reviews_Amazon_Instant_Video_5.json.gz')\n",
    "            df = self.getDF('./data/reviews_Musical_Instruments_5.json.gz')\n",
    "    #         display(self.df)\n",
    "    #         print(self.df.loc[0][['overall','reviewText']])\n",
    "            df = df[['reviewText', 'overall']]\n",
    "            df['reviewText'] = df['reviewText'].apply(lambda x : self.title_parsing(x))\n",
    "            X = df['reviewText']\n",
    "            y = df['overall']-1\n",
    "            self.weight_matrix = self.get_weigth_matrix(X)\n",
    "            X = self.indicesMatrix(X)\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            \n",
    "            \n",
    "        def title_parsing(self, title):  \n",
    "            # remove stop words and tokenization \n",
    "            title = re.sub('[^a-zA-Z]', ' ', str(title))\n",
    "            title = title.lower()\n",
    "            title = remove_stopwords(title)  ## remove stop words, corpus size 52680            \n",
    "            title = title.split()\n",
    "            title = [word for word in title if len(word) >1 ]\n",
    "            return title\n",
    "        \n",
    "        \n",
    "        def parse(self, path):\n",
    "            g = gzip.open(path, 'rb')\n",
    "            for l in g:\n",
    "                yield eval(l)\n",
    "            \n",
    "        def getDF(self, path):\n",
    "            i = 0\n",
    "            df = {}\n",
    "            for d in self.parse(path):\n",
    "                df[i] = d\n",
    "                i += 1\n",
    "            return pd.DataFrame.from_dict(df, orient='index')        \n",
    "\n",
    "        def buildCorpus(self, X):\n",
    "            '''\n",
    "            return a dictionary with 'word' and its index in corpus as key and value respectively\n",
    "            '''\n",
    "            word2idx = {}\n",
    "            idx2word = [] ## alternatively use if.. condition\n",
    "            idx = 0 \n",
    "            for row in X:\n",
    "                for word in row:\n",
    "                    if word not in word2idx:\n",
    "                        idx2word.append(word)                \n",
    "                        word2idx[word] = len(idx2word) - 1\n",
    "#             pickle.dump(word2idx, open('./data/corpusDict.txt', 'wb'))\n",
    "            return word2idx   \n",
    "        \n",
    "    \n",
    "        def indicesMatrix(self, X):\n",
    "            '''\n",
    "            return matrix (num_reviews, maxNumberWords) such that review text transformed to index\n",
    "            '''\n",
    "            word2idx = self.buildCorpus(X)\n",
    "#             word2idx = pickle.load(open('./data/corpusDict.txt', 'rb'))\n",
    "            ## 53008 words in corpus\n",
    "    \n",
    "            corpusSize = len(word2idx) \n",
    "        \n",
    "            ###\n",
    "            k = sorted(len(x) for x in X)\n",
    "            plt.hist(k)\n",
    "            ###\n",
    "            \n",
    "#             maxNumberWords = sorted(len(x) for x in X)[-1]\n",
    "#             print (\"maximum\", maxNumberWords)\n",
    "            maxNumberWords =25\n",
    "\n",
    "            index_matrix = np.zeros((X.shape[0], maxNumberWords))          \n",
    "            for i, row in enumerate(X):\n",
    "                for j, word in enumerate(row):\n",
    "#                     try:\n",
    "#                         index_matrix[i,j] = word2idx[word]\n",
    "#                         words_found += 1\n",
    "#                     except KeyError:\n",
    "#                         index_matrix[i,j] = corpusSize     \n",
    "\n",
    "                    index_matrix[i,j] = word2idx[word]\n",
    "                    if j >= maxNumberWords-1 : \n",
    "                        break\n",
    "            if maxNumberWords % 2 == 1:\n",
    "                x0 = np.full((index_matrix.shape[0], 1), maxNumberWords)\n",
    "                index_matrix = np.hstack((index_matrix, x0))\n",
    "            return index_matrix\n",
    "        \n",
    "        def get_weigth_matrix(self, X): #max norm for linear layer\n",
    "            '''\n",
    "            return matrix contains embedding for word in corpus/review text\n",
    "            Note that the word cannot be found in the glove returns ?? as embedding\n",
    "            '''\n",
    "\n",
    "            glove = {}\n",
    "\n",
    "            with open(f'./data/glove.twitter.27B.100d.txt', 'rb') as f:#\n",
    "                for l in f:\n",
    "                    line = l.decode().split()           \n",
    "                    word = line[0]\n",
    "        #            words.append(word)\n",
    "        #             word2idx[word] = idx\n",
    "        #            idx += 1\n",
    "                    vect = np.array(line[1:]).astype(np.float)\n",
    "        #             vectors.append(vect)\n",
    "        #     vectors = np.reshape(vectors, (400000, 50))\n",
    "                    glove.update({word:vect})\n",
    "        #     glove = {word2idx[w]: vectors[word2idx[w]] for w in words}  # alternatively generate weights_matrix directly\n",
    "\n",
    "            target_vocab = self.buildCorpus(X)\n",
    "            #except\n",
    "            #exceptKey = list(set(list(glove.keys())).difference(list(target_vocab.keys())))  ## \n",
    "            matrix_len = len(target_vocab)\n",
    "            weights_matrix = np.zeros((matrix_len, 100))#\n",
    "            words_found = 0\n",
    "            words_not_found = 0\n",
    "            for i, word in enumerate(target_vocab):\n",
    "                try: \n",
    "                    weights_matrix[i] = glove[word]\n",
    "                    words_found += 1\n",
    "                except KeyError:\n",
    "                    words_not_found += 1\n",
    "                    weights_matrix[i] = np.random.normal(scale=0.6, size=(100,))#\n",
    "\n",
    "            print(words_not_found)\n",
    "            return  weights_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3313\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAD4tJREFUeJzt3W2sXVWdx/Hvb6jAiFGKVIMtmZbYqGjiQBoEnUwm4PCksbyApMaMjdOkb5gRjYkDMy+aUUkkMaImI5EIDmOMyFQyNEgkpOCLeWGliEGgMr2CA1dQrmnBGY0P1f+8OOsuDp17e59O723v/X6Sk7P3f699zlpn3eTXvc/ep6kqJEkC+JOl7oAk6dhhKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUrdqqTtwJKeffnqtX79+qbshSceVhx566BdVtWY++x7TobB+/Xr27t271N2QpONKkv+e776ePpIkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1x/QdzQu1/tpvLcn7/uTT71mS95WkhfJIQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1swqFJB9N8liSR5N8PcnJSTYk2ZNkf5JvJDmxtT2prY+17euHXue6Vn8iySVHZ0iSpPmaMRSSrAU+DGyqqrcBJwBbgBuAG6tqI3AQ2NZ22QYcrKo3Aje2diQ5u+33VuBS4ItJThjtcCRJCzHb00ergD9Nsgp4JfAccCGws22/DbiiLW9u67TtFyVJq99eVb+tqqeAMeC8hQ9BkjQqM4ZCVf0U+AzwNIMweBF4CHihqg61ZuPA2ra8Fnim7XuotX/tcH2KfSRJx4DZnD5azeBf+RuANwCnAJdN0bQmd5lm23T1w99ve5K9SfZOTEzM1D1J0gjN5vTRu4Gnqmqiqn4P3Am8Ezi1nU4CWAc825bHgTMB2vbXAAeG61Ps01XVzVW1qao2rVmzZh5DkiTN12xC4Wng/CSvbN8NXAQ8DjwAXNnabAXuasu72jpt+/1VVa2+pV2dtAHYCHxvNMOQJI3CqpkaVNWeJDuB7wOHgIeBm4FvAbcn+VSr3dJ2uQX4apIxBkcIW9rrPJbkDgaBcgi4uqr+MOLxSJIWYMZQAKiqHcCOw8pPMsXVQ1X1G+CqaV7neuD6OfZRkrRIvKNZktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdbMKhSSnJtmZ5EdJ9iW5IMlpSe5Lsr89r25tk+QLScaSPJLk3KHX2dra70+y9WgNSpI0P7M9Uvg88O2qejPwdmAfcC2wu6o2ArvbOsBlwMb22A7cBJDkNGAH8A7gPGDHZJBIko4NM4ZCklcDfwncAlBVv6uqF4DNwG2t2W3AFW15M/BvNfBd4NQkZwCXAPdV1YGqOgjcB1w60tFIkhZkNkcKZwETwFeSPJzky0lOAV5fVc8BtOfXtfZrgWeG9h9vtenqkqRjxGxCYRVwLnBTVZ0D/IqXThVNJVPU6gj1l++cbE+yN8neiYmJWXRPkjQqswmFcWC8qva09Z0MQuLn7bQQ7fn5ofZnDu2/Dnj2CPWXqaqbq2pTVW1as2bNXMYiSVqgGUOhqn4GPJPkTa10EfA4sAuYvIJoK3BXW94FfLBdhXQ+8GI7vXQvcHGS1e0L5otbTZJ0jFg1y3Z/D3wtyYnAk8CHGATKHUm2AU8DV7W29wCXA2PAr1tbqupAkk8CD7Z2n6iqAyMZhSRpJGYVClX1A2DTFJsumqJtAVdP8zq3ArfOpYOSpMXjHc2SpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpm3UoJDkhycNJ7m7rG5LsSbI/yTeSnNjqJ7X1sbZ9/dBrXNfqTyS5ZNSDkSQtzFyOFK4B9g2t3wDcWFUbgYPAtlbfBhysqjcCN7Z2JDkb2AK8FbgU+GKSExbWfUnSKM0qFJKsA94DfLmtB7gQ2Nma3AZc0ZY3t3Xa9ota+83A7VX126p6ChgDzhvFICRJozHbI4XPAR8H/tjWXwu8UFWH2vo4sLYtrwWeAWjbX2zte32Kfbok25PsTbJ3YmJiDkORJC3UjKGQ5L3A81X10HB5iqY1w7Yj7fNSoermqtpUVZvWrFkzU/ckSSO0ahZt3gW8L8nlwMnAqxkcOZyaZFU7GlgHPNvajwNnAuNJVgGvAQ4M1ScN7yNJOgbMeKRQVddV1bqqWs/gi+L7q+oDwAPAla3ZVuCutryrrdO2319V1epb2tVJG4CNwPdGNhJJ0oLN5khhOv8A3J7kU8DDwC2tfgvw1SRjDI4QtgBU1WNJ7gAeBw4BV1fVHxbw/pKkEZtTKFTVd4DvtOUnmeLqoar6DXDVNPtfD1w/105KkhaHdzRLkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktTNGApJzkzyQJJ9SR5Lck2rn5bkviT72/PqVk+SLyQZS/JIknOHXmtra78/ydajNyxJ0nzM5kjhEPCxqnoLcD5wdZKzgWuB3VW1Edjd1gEuAza2x3bgJhiECLADeAdwHrBjMkgkSceGGUOhqp6rqu+35f8B9gFrgc3Aba3ZbcAVbXkz8G818F3g1CRnAJcA91XVgao6CNwHXDrS0UiSFmRO3ykkWQ+cA+wBXl9Vz8EgOIDXtWZrgWeGdhtvtenqkqRjxKxDIcmrgG8CH6mqXx6p6RS1OkL98PfZnmRvkr0TExOz7Z4kaQRmFQpJXsEgEL5WVXe28s/baSHa8/OtPg6cObT7OuDZI9RfpqpurqpNVbVpzZo1cxmLJGmBZnP1UYBbgH1V9dmhTbuAySuItgJ3DdU/2K5COh94sZ1euhe4OMnq9gXzxa0mSTpGrJpFm3cBfwP8MMkPWu0fgU8DdyTZBjwNXNW23QNcDowBvwY+BFBVB5J8EniwtftEVR0YySgkSSMxYyhU1X8y9fcBABdN0b6Aq6d5rVuBW+fSQUnS4vGOZklSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkrpVS92B5Wj9td9akvf9yaffsyTvK2n58EhBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJK6RQ+FJJcmeSLJWJJrF/v9JUnTW9Q7mpOcAPwL8NfAOPBgkl1V9fhi9mO5Wqo7qcG7qaXlYrGPFM4Dxqrqyar6HXA7sHmR+yBJmsZi//bRWuCZofVx4B2L3AcdBf7ek7Q8LHYoZIpavaxBsh3Y3lb/N8kTC3i/04FfLGD/49WKGXdu+H+lFTP2KTj2lWmqsf/ZfF9ssUNhHDhzaH0d8Oxwg6q6Gbh5FG+WZG9VbRrFax1PVuq4wbE79pVn1GNf7O8UHgQ2JtmQ5ERgC7BrkfsgSZrGoh4pVNWhJH8H3AucANxaVY8tZh8kSdNb9P9kp6ruAe5ZpLcbyWmo49BKHTc49pXKsY9IqmrmVpKkFcGfuZAkdcsyFJb7T2kkOTPJA0n2JXksyTWtflqS+5Lsb8+rWz1JvtA+j0eSnLu0I1i4JCckeTjJ3W19Q5I9bezfaBcykOSktj7Wtq9fyn4vVJJTk+xM8qM2/xeslHlP8tH29/5okq8nOXm5znuSW5M8n+TRodqc5znJ1tZ+f5Kts3nvZRcKQz+lcRlwNvD+JGcvba9G7hDwsap6C3A+cHUb47XA7qraCOxu6zD4LDa2x3bgpsXv8shdA+wbWr8BuLGN/SCwrdW3AQer6o3Aja3d8ezzwLer6s3A2xl8Bst+3pOsBT4MbKqqtzG4UGULy3fe/xW49LDanOY5yWnADgY3CJ8H7JgMkiOqqmX1AC4A7h1avw64bqn7dZTHfBeD35N6Ajij1c4AnmjLXwLeP9S+tzseHwzub9kNXAjczeCmyF8Aqw7/G2BwpdsFbXlVa5elHsM8x/1q4KnD+78S5p2Xfg3htDaPdwOXLOd5B9YDj853noH3A18aqr+s3XSPZXekwNQ/pbF2ifpy1LXD4nOAPcDrq+o5gPb8utZsuX0mnwM+Dvyxrb8WeKGqDrX14fH1sbftL7b2x6OzgAngK+3U2ZeTnMIKmPeq+inwGeBp4DkG8/gQK2PeJ811nuc1/8sxFGb8KY3lIsmrgG8CH6mqXx6p6RS14/IzSfJe4Pmqemi4PEXTmsW2480q4Fzgpqo6B/gVL51CmMqyGXs77bEZ2AC8ATiFwWmTwy3HeZ/JdGOd12ewHENhxp/SWA6SvIJBIHytqu5s5Z8nOaNtPwN4vtWX02fyLuB9SX7C4Fd2L2Rw5HBqksn7bobH18fetr8GOLCYHR6hcWC8qva09Z0MQmIlzPu7gaeqaqKqfg/cCbyTlTHvk+Y6z/Oa/+UYCsv+pzSSBLgF2FdVnx3atAuYvMJgK4PvGibrH2xXKZwPvDh5GHq8qarrqmpdVa1nMLf3V9UHgAeAK1uzw8c++Zlc2dofl/9irKqfAc8keVMrXQQ8zgqYdwanjc5P8sr29z859mU/70PmOs/3AhcnWd2OtC5utSNb6i9TjtIXNJcD/wX8GPinpe7PURjfXzA4DHwE+EF7XM7gnOluYH97Pq21D4Mrsn4M/JDBFRxLPo4RfA5/Bdzdls8CvgeMAf8OnNTqJ7f1sbb9rKXu9wLH/OfA3jb3/wGsXinzDvwz8CPgUeCrwEnLdd6BrzP47uT3DP7Fv20+8wz8bfsMxoAPzea9vaNZktQtx9NHkqR5MhQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdf8HNQauatqHy3YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_loader = AmznDataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7191569541569541"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(data_loader.X_train)/(data_loader.X_train.shape[0]*data_loader.X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29700, 26)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.X_train.shape\n",
    "# data_loader.buildCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.275466918945312\n"
     ]
    }
   ],
   "source": [
    "weight_matrix = data_loader.weight_matrix\n",
    "import sys\n",
    "print(sys.getsizeof(weight_matrix)/(2**20))\n",
    "\n",
    "# print(weight_matrix[0])\n",
    "# print(weight_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(weight_matrix,  open('./data/GloveMatrix.npy', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo reset parameters for linear layer\n",
    "class ReviewModel(nn.Module):\n",
    "    def __init__(self, max_length, batch_size):\n",
    "        super(ReviewModel, self).__init__()\n",
    "        weights_matrix = data_loader.weight_matrix\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(weights_matrix), freeze=False)\n",
    "#        self.embedding = nn.Embedding(weights_matrix.shape[0],weights_matrix.shape[1])\n",
    "#         self.embedding.weight.data.copy_(torch.from_numpy(weights_matrix))\n",
    "        self.drop1 = nn.Dropout(p=0.5)\n",
    "        self.conv1 = nn.Conv1d(in_channels=100, out_channels=200, kernel_size=4, padding=2).double()#\n",
    "        self.conv2 = nn.Conv1d(in_channels=100, out_channels=200, kernel_size=5, padding=2).double()#\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.drop2 = nn.Dropout(p=0.15)\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=400, hidden_size=100, num_layers=1, batch_first=False)  #\n",
    "#        self.fc1 =nn.Linear(in_features=1501*100, out_features = 400)\n",
    "        self.fc1 =nn.Linear(in_features=(max_length//2)*100, out_features = 400)\n",
    "        self.drop3 = nn.Dropout(p=0.1)\n",
    "        self.fc2 = nn.Linear(in_features=400, out_features=5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         print(\"input tensor\", x.size())\n",
    "        x = self.embedding(x)\n",
    "#         print(\"after embedding\", x.size())\n",
    "        x = self.drop1(x)\n",
    "#        print(x)\n",
    "        x = x.view(-1,100,self.max_length)  # input(N,C_in,L) to conv1d\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "#         print(\"x1 shape\", x1.size())\n",
    "        x2 = F.relu(self.conv2(x))\n",
    "#         print(\"x2 shape \", x2.size())\n",
    "\n",
    "        x1 = self.maxpool(x1)\n",
    "#         print(\"x1 shape\", x1.size())        \n",
    "        x2 = self.maxpool(x2)\n",
    "#         print(\"x2 shape\", x2.size())        \n",
    "        x = torch.cat((x1,x2), 1)\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        x = x.view((self.max_length//2),-1, 400).float()#### change dimensionality\n",
    "        \n",
    "        hidden = Variable(torch.cuda.FloatTensor(1, batch_size, 100).uniform_()) \n",
    "        \n",
    "#        print(\"before rnn \", x.size(), \"hidden size \",hidden.size())\n",
    "\n",
    "        output, _ = self.rnn(x,hidden)\n",
    "#         print(\"AFTER rnn \",output.size())\n",
    "        \n",
    "        x = output.contiguous().view(-1, (self.max_length//2)*100)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "#     def create_emb_layer(self, weights_matrix, non_trainable=True):\n",
    "#         num_embeddings, embedding_dim = weights_matrix.shape\n",
    "#         emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "#         emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "#         if non_trainable:\n",
    "#             emb_layer.weight.requires_grad = False\n",
    "\n",
    "#         return emb_layer, num_embeddings, embedding_dim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter(data_loader.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.0, 22.757575757575758),\n",
       " (4.0, 56.18518518518518),\n",
       " (0.0, 4.562289562289562),\n",
       " (2.0, 11.26936026936027),\n",
       " (1.0, 5.225589225589226)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, c[i]/len(data_loader.y_train)*100) for i in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = Variable(torch.cuda.FloatTensor([0.4,0.5,0.11,0.23,0.56])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import EpochScoring, PrintLog, ProgressBar, LRScheduler, EarlyStopping\n",
    "from sklearn.metrics import accuracy_score,make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_accuracy(net, ds, y=None):\n",
    "    # assume ds yields (X, y), e.g. torchvision.datasets.MNIST\n",
    "    y_true = [y for _, y in ds]\n",
    "    y_pred = net.predict(ds)\n",
    "    return sklearn.metrics.accuracy_score(y_true, y_pred)\n",
    "    \n",
    "\n",
    "callbacks = [\n",
    "    ('es1',EpochScoring('accuracy')),\n",
    "    ('lrs',LRScheduler()),\n",
    "    ('est',EarlyStopping()),\n",
    "    \n",
    "]\n",
    "\n",
    "batch_size = 256\n",
    "device = torch.device(\"cuda\")\n",
    "model = ReviewModel(data_loader.X_train.shape[1], batch_size).to(device)\n",
    "net = NeuralNetClassifier(model,## change dimensionality\n",
    "                          iterator_train__drop_last = True,\n",
    "                          iterator_valid__drop_last = True, \n",
    "                          iterator_train__shuffle = True,\n",
    "                          iterator_valid__shuffle = True,\n",
    "                          max_epochs=100, \n",
    "                          criterion = nn.CrossEntropyLoss, \n",
    "                          #criterion__weight = weight, \n",
    "                          optimizer=optim.Adadelta,\n",
    "                          optimizer__param_groups =[('eps', 1e-06),('lr', 0.95)],\n",
    "                          batch_size = batch_size,\n",
    "                          callbacks = callbacks,\n",
    "                          device = device,verbose = 1\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'lr': [0.001, 0.005, 0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "#     'max_epochs': list(range(10,100,20))\n",
    "# }\n",
    "# gs = GridSearchCV(net, params, refit = False, scoring = 'accuracy',verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    accuracy    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.6738\u001b[0m        \u001b[32m1.0982\u001b[0m       \u001b[35m0.6738\u001b[0m        \u001b[31m0.9722\u001b[0m  7.4857\n",
      "      2      0.6764        \u001b[32m0.9552\u001b[0m       \u001b[35m0.6764\u001b[0m        \u001b[31m0.9585\u001b[0m  7.4702\n",
      "      3      0.6764        \u001b[32m0.9523\u001b[0m       0.6764        0.9609  7.4712\n",
      "      4      0.6751        \u001b[32m0.9508\u001b[0m       0.6751        0.9671  7.4738\n",
      "      5      0.6738        0.9524       0.6738        0.9650  7.4724\n",
      "      6      \u001b[36m0.6719\u001b[0m        0.9535       0.6719        0.9728  7.4734\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ReviewModel(\n",
       "    (embedding): Embedding(18711, 100)\n",
       "    (drop1): Dropout(p=0.5)\n",
       "    (conv1): Conv1d(100, 200, kernel_size=(4,), stride=(1,), padding=(2,))\n",
       "    (conv2): Conv1d(100, 200, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (drop2): Dropout(p=0.15)\n",
       "    (rnn): GRU(400, 100)\n",
       "    (fc1): Linear(in_features=1300, out_features=400, bias=True)\n",
       "    (drop3): Dropout(p=0.1)\n",
       "    (fc2): Linear(in_features=400, out_features=5, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.from_numpy(data_loader.X_train).long().to(device)\n",
    "labels = torch.tensor(data_loader.y_train.values).long().to(device)\n",
    "# rest = inputs.size()[0] % batch_size\n",
    "# print(rest)\n",
    "# print(inputs.size())\n",
    "# inputs = inputs[:-rest]\n",
    "# print(inputs.size()[0]/batch_size)\n",
    "# print(inputs.shape)\n",
    "# labels = labels[:-rest]\n",
    "net.fit(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open(\"model.pkl\", 'wb') as f:\n",
    "    pickle.dump(\"model\",f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.pkl\",\"rb\") as f: \n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = data_loader.indicesMatrix()\n",
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(tr_loss, val_loss):\n",
    "    plt.plot(tr_loss, label=\"training\")\n",
    "    plt.plot(val_loss, label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo plot losses\n",
    "#todo plot accuracy\n",
    "#todo confusion matrix\n",
    "history = net.history\n",
    "train_losses = history[:, 'train_loss']\n",
    "valid_losses = history[:, 'valid_loss']\n",
    "\n",
    "accuracy = history[:, 'accuracy']\n",
    "plot_losses(train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
